{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réalisez un détecteur de slides grâce à de l'analyse d'image\n",
    "\n",
    "## Fonctions outils\n",
    "\n",
    "(code à exécuter sans y prêter attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "# dimensions des images\n",
    "height = 72\n",
    "width = 128\n",
    "\n",
    "# Fonctions d'affichage des images\n",
    "def display_image(video, image_position):\n",
    "    try:\n",
    "        img = video[video.position == image_position]\n",
    "        url = img.index.values[0]\n",
    "        img = img.values[0]\n",
    "    except IndexError:\n",
    "        raise Exception(\"La position demandée n'est pas disponible\")\n",
    "    img = img[1:] # On supprime la première colonne qui correspond à la position de l'image (en secondes)\n",
    "    \n",
    "    display_with_pylab(img, url)\n",
    "    \n",
    "def display_compressed_image(pca, std_scaler, X_projected, image_position, list_of_positions):\n",
    "    try:\n",
    "        i = np.where(list_of_positions == image_position)[0][0]\n",
    "    except IndexError:\n",
    "        raise Exception(\"La position demandée n'est pas disponible\")\n",
    "        \n",
    "    compressed_img = X_projected[i]\n",
    "    img = decompress_image(pca, std_scaler, compressed_img)\n",
    "    url = list_of_positions.index[i]\n",
    "    \n",
    "    display_with_pylab(img, url)\n",
    "\n",
    "def display_with_pylab(img, url=None):\n",
    "    img = img.reshape(height, width, 3) # On remet l'image sous forme d'un numpy array de height*width*3\n",
    "    img = img * 4 # On remet l'échelle des couleurs de 0 à 256\n",
    "    img = np.array(img, dtype=np.float64)\n",
    "    if url:\n",
    "        print(url)\n",
    "    fig = pylab.figure()\n",
    "    pylab.imshow(img.astype(np.uint8))\n",
    "    plt.show()   \n",
    "    \n",
    "def decompress_image(pca, std_scaler, compressed_img):\n",
    "    img = pca.inverse_transform(compressed_img)\n",
    "    img = std_scaler.inverse_transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Nous importons le CSV et stockons la matrice dans un array numpy appelé X. Cette opération peut prendre quelques secondes. Ensuite, nous affichons l'image de la 150e seconde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la vidéo (peut prendre quelques secondes)\n",
    "try:\n",
    "    video\n",
    "except NameError:\n",
    "    video = pd.read_csv(\"video.csv\", index_col= 0)\n",
    "    \n",
    "display_image(video,150)\n",
    "print(video)\n",
    "\n",
    "X = video.values[:,1:] # On supprime la première colonne qui correspond à la position de l'image (en secondes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP et réduction de dimensions\n",
    "\n",
    "Comme il y a beaucoup de colonnes, nous réduisons les données grâce à une ACP après centrage-réduction des données. Nous remplaçons donc toutes nos colonnes par les  n_comp  premières composantes principales, pour avoir un tableau de données avec  n_comp  colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 60\n",
    "\n",
    "# centrage-réduction\n",
    "X = X.astype(np.float64) # conversion des nombres entiers en nombres décimaux (float) : necessaire pour le StandardScaler\n",
    "std_scaler = preprocessing.StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#B11D1D\">__**Code à compléter :**__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = ###[...]###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des composantes principales\n",
    "pca = decomposition.PCA(n_components= n_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#B11D1D\">__**Code à compléter :**__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.###[...]###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_projected = pca.transform(X_scaled)\n",
    "\n",
    "# Affichage des éboulis\n",
    "eboulis = pca.explained_variance_ratio_*100\n",
    "plt.bar(np.arange(len(eboulis))+1, eboulis)\n",
    "plt.plot(np.arange(len(eboulis))+1, eboulis.cumsum(),c=\"red\",marker='o')\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "plt.ylabel(\"pourcentage d'inertie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquez que nous avons ici effectué une compression de vidéo ! Il existe des formats informatiques d'images ou de vidéos compressées (jpeg, mp4, etc.). Certains de ceux-ci se basent sur des méthodes de compressions similaires à l'ACP !\n",
    "\n",
    "Le calcul des composantes principales peut prendre ici plusieurs secondes, soyez patient. ;)\n",
    "\n",
    "Après compression de la vidéo, on a forcément perdu en qualité. Affichons l'image de la 150e seconde pour voir cette perte de qualité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_compressed_image(pca, std_scaler, X_projected, 150, video[\"position\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En affichant les individus projetés sur les premiers plans factoriels, on voit déjà quelques groupes d'images similaires.\n",
    "\n",
    "Pour les visionner, rendez-vous à cette URL, https://www.youtube.com/watch?v=uV5hmpzmWsU?t=[...]s, en remplaçant le [...] par l'identifiant du point à visualiser. Cet identifiant correspond à la position de l'image dans la vidéo ; il est donné en secondes. Vous pouvez vérifier si deux points proches correspondent à deux images qui se ressemblent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des 5 premiers plans factoriels\n",
    "for d1,d2 in [(0,1),(2,3),(4,5),(6,7),(8,9)]:\n",
    "    if d2 < n_comp:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha= 0.5)\n",
    "        \n",
    "        # On identifie les images par leur position dans la vidéo (en secondes)\n",
    "        for i in range(len(X_projected)):\n",
    "            plt.text(X_projected[i, d1], X_projected[i, d2], video[\"position\"][i], alpha= 0.4)\n",
    "\n",
    "        # nom des axes\n",
    "        plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "        plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Nous allons regrouper les images similaires. L'idéal serait d'avoir un groupe par slide différente.\n",
    "\n",
    "Nous allons donc effectuer une classification hiérarchique et afficher le dendrogramme pour choisir le nombre de classes.\n",
    "\n",
    "Cependant, il y a trop d'individus (trop d'images) pour effectuer une C.H. rapidement. Nous allons donc d'abord effectuer un clustering avec k-means afin de trouver 300 clusters, en espérant que le professeur n'ait pas plus de 300 slides. Il est fort probable qu'après l'application du k-means, plusieurs clusters correspondent à une même slide : c'est là que la classification hiérarchique sera utile afin de regrouper les clusters correspondant à une même slide.\n",
    "\n",
    "Remarquons qu'ici, on applique le k-means aux données compressées après ACP, c'est-à-dire à X_projected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters= 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#B11D1D\">__**Code à compléter :**__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.###[...]###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_kmeans = km.labels_\n",
    "centroids_after_kmeans = km.cluster_centers_\n",
    "print(centroids_after_kmeans.shape) # 300 centres de n_comp dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme les centres de classes sont des points qui ont le même nombre de dimensions (n_comp dimensions) que nos images compressées, on peut afficher ces centres comme des images !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = decompress_image(pca, std_scaler, centroids_after_kmeans[3]) # On choisit au hasard le cluster numéro 4\n",
    "display_with_pylab(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant effectuer la classification hiérarchique sur les 300 clusters. Le professeur a environ 40 slides différentes. Coupons donc l'arbre en 40 clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(centroids_after_kmeans, 'ward')\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.ylabel('distance')\n",
    "dendrogram(Z, no_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#B11D1D\">__**Code à compléter :**__</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clusters = ###[...]###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On arrive ainsi à définir quelle image appartient à quel cluster final. Pour chaque cluster, on pioche au hasard une image (on peut prendre par exemple celle qui apparaît en premier), et on l'affiche. En théorie, on ne devrait donc afficher qu'une image par slide. Nous avons atteint notre objectif !\n",
    "\n",
    "## Résultat\n",
    "\n",
    "On affiche aussi l'image moyenne du cluster. Elle représente une \"image moyenne\" composée de plusieurs images. Sur celles-ci, les objets fixes seront nets, et les objets mobiles seront flous. Les slides seront donc nettement visibles !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in range(max(final_clusters)):\n",
    "    g = g + 1\n",
    "    print('-'*30,\"\\nSlide n° \", g)\n",
    "    km_centers = np.where(final_clusters == g)[0] # renvoie les indexes des centres issus du kmeans qui ont été groupés dans le groupe g après la classification hiérarchique\n",
    "    img_ind = np.where([c in km_centers for c in clusters_kmeans]) # renvoie les indexes des images similaires, groupées par kmeans puis par classification hiérarchique\n",
    "    same_slide = video.iloc[img_ind] # renvoie toutes les images montrant une même slide\n",
    "    first_image = same_slide.sort_values(\"position\").iloc[0]\n",
    "    \n",
    "    print(\"Première image :\")\n",
    "    display_image(video, first_image[\"position\"])\n",
    "    \n",
    "    print(\"Image moyenne de tout le cluster\")\n",
    "    print(\"(Nombre d'images dans le cluster :{})\".format(len(same_slide)))\n",
    "\n",
    "    average_image = same_slide.iloc[:,1:].mean()   \n",
    "    display_with_pylab(np.array(average_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
