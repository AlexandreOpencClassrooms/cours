{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d846cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1. Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838406",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1 Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79995afa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* We will analyze a very well known NLP dataset: tweets from disaster\n",
    "\n",
    "\n",
    "* It is a Kaggle competition, which offers a simple but good level textual dataset to be able to make its weapons in NLP\n",
    "\n",
    "\n",
    "* The dataset is here [https://www.kaggle.com/competitions/nlp-getting-started/data]\n",
    "\n",
    "\n",
    "* Please use the **train** dataset\n",
    "\n",
    "\n",
    "* In this 1st part we are going to clean the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562f101",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.2 Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885639a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T20:47:48.424652Z",
     "start_time": "2022-06-28T20:47:48.419964Z"
    },
    "hidden": true
   },
   "source": [
    "You have to install  : \n",
    "\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* seaborn\n",
    "\n",
    "\n",
    "* nltk\n",
    "* wordcloud\n",
    "* pillow\n",
    "\n",
    "\n",
    "* pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97396f16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.3 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dbd5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.009256Z",
     "start_time": "2022-06-30T19:16:36.215364Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# builtin\n",
    "import os, sys, time, random\n",
    "\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# import spacy\n",
    "\n",
    "\n",
    "# viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "# import plotly as px\n",
    "\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a272cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.4 Downloads and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f872b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.022842Z",
     "start_time": "2022-06-30T19:16:38.012575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# download\n",
    "\n",
    "\"\"\"\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ce93e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.031376Z",
     "start_time": "2022-06-30T19:16:38.024770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, \n",
    "                       nb_workers=6, \n",
    "                       # verbose=1\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb0d63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.039867Z",
     "start_time": "2022-06-30T19:16:38.035459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# init sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b4148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.047046Z",
     "start_time": "2022-06-30T19:16:38.042525Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# init pandarallel\n",
    "\n",
    "# pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880a917",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.5 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046fdbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.055967Z",
     "start_time": "2022-06-30T19:16:38.049670Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# our file\n",
    "\n",
    "data = \"./data/cleaned/\"\n",
    "os.listdir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699e715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.097919Z",
     "start_time": "2022-06-30T19:16:38.059017Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "\n",
    "fn = data + 'df_cleaned.csv'\n",
    "df = pd.read_csv(fn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10fbf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.107443Z",
     "start_time": "2022-06-30T19:16:38.101002Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced76f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.114328Z",
     "start_time": "2022-06-30T19:16:38.110173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df =df.sample(frac=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d39a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.123102Z",
     "start_time": "2022-06-30T19:16:38.118671Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab788d1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2. Work on a specific document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea19425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.131779Z",
     "start_time": "2022-06-30T19:16:38.125625Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# select a random document\n",
    "\n",
    "doc = df.text.sample(1)\n",
    "doc = doc.values[0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86b385",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.1 Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1754801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.138929Z",
     "start_time": "2022-06-30T19:16:38.134131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# lower\n",
    "\n",
    "doc = doc.lower()\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac2ec5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5c20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.155177Z",
     "start_time": "2022-06-30T19:16:38.141163Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "\n",
    "tokens = word_tokenize(doc)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09531ad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.163472Z",
     "start_time": "2022-06-30T19:16:38.157645Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7ca33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.172351Z",
     "start_time": "2022-06-30T19:16:38.166686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc474bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.178740Z",
     "start_time": "2022-06-30T19:16:38.175076Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_tokens_info(tokens) : \n",
    "    \"\"\"display info about corpus \"\"\"\n",
    "    \n",
    "    print(f\"taille corpus {len(tokens)}, nb tokens uniques {len(set(tokens))}\")\n",
    "    print(tokens[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a396b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.185240Z",
     "start_time": "2022-06-30T19:16:38.181148Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# an other tokenize\n",
    "\n",
    "tokens = wordpunct_tokenize(doc)\n",
    "display_tokens_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dee43c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.3 Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ec4db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.192671Z",
     "start_time": "2022-06-30T19:16:38.187856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stop_words\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4792ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.199968Z",
     "start_time": "2022-06-30T19:16:38.195352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokens = [w for w in tokens if w not in stop_words]\n",
    "display_tokens_info(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda51a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.207681Z",
     "start_time": "2022-06-30T19:16:38.202858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# an other tokensizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(doc)\n",
    "display_tokens_info(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57384b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.214724Z",
     "start_time": "2022-06-30T19:16:38.210309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "\n",
    "tokens = [w for w in tokens if w not in stop_words]\n",
    "display_tokens_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494c560",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.4 First cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd3174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.222625Z",
     "start_time": "2022-06-30T19:16:38.217674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_text_1(doc, rejoin=False) : \n",
    "    \"\"\"basic function of text processing \"\"\"\n",
    "    \n",
    "    # lower\n",
    "    doc = doc.lower().strip()\n",
    "    \n",
    "    # tokenize\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # stop words\n",
    "    cleaned_tokens_list = [w for w in raw_tokens_list if w not in stop_words]\n",
    "    \n",
    "    if rejoin : \n",
    "        return \" \".join(cleaned_tokens_list)\n",
    "    \n",
    "    return cleaned_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafd633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.229613Z",
     "start_time": "2022-06-30T19:16:38.225406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokens = process_text_1(doc)\n",
    "display_tokens_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbdea23",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Working on the entire corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66489ad6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1 Build raw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ce4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.240005Z",
     "start_time": "2022-06-30T19:16:38.233528Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# join all corpus\n",
    "\n",
    "raw_corpus = \"\".join(df.text.values)\n",
    "raw_corpus[:1_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af82dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.272909Z",
     "start_time": "2022-06-30T19:16:38.243377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# process the corpus\n",
    "\n",
    "corpus = process_text_1(raw_corpus)\n",
    "display_tokens_info(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202abe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.291374Z",
     "start_time": "2022-06-30T19:16:38.275225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# value counts\n",
    "\n",
    "tmp = pd.Series(corpus).value_counts()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ff84d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.297751Z",
     "start_time": "2022-06-30T19:16:38.294274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "\n",
    "# sns.barplot(x=tmp.index, y=tmp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e385b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.315041Z",
     "start_time": "2022-06-30T19:16:38.308606Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 30st most common tokens\n",
    "\n",
    "tmp.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d809e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.325302Z",
     "start_time": "2022-06-30T19:16:38.317868Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 30st last common tokens\n",
    "\n",
    "tmp.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c0079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.338398Z",
     "start_time": "2022-06-30T19:16:38.328307Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a9a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.343817Z",
     "start_time": "2022-06-30T19:16:38.340828Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sns.displot(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c76df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.351673Z",
     "start_time": "2022-06-30T19:16:38.346727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sns.boxplot(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15905e9c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.2 List rare tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca7018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.370445Z",
     "start_time": "2022-06-30T19:16:38.354205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# unique words --> not usefull\n",
    "\n",
    "tmp = pd.Series(corpus).value_counts()\n",
    "list_unique_words = tmp[tmp==1]\n",
    "list_unique_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ccc02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.377374Z",
     "start_time": "2022-06-30T19:16:38.372660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(list_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9b8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.387146Z",
     "start_time": "2022-06-30T19:16:38.380228Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_unique_words = list(list_unique_words.index)\n",
    "list_unique_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a7568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.407996Z",
     "start_time": "2022-06-30T19:16:38.389570Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save it for later\n",
    "\n",
    "tmp = pd.DataFrame({\"words\" : list_unique_words})\n",
    "tmp.to_csv(\"data/cleaned/unique_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07325ab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.428047Z",
     "start_time": "2022-06-30T19:16:38.410799Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# idem for min 5 times\n",
    "\n",
    "tmp = pd.Series(corpus).value_counts()\n",
    "list_min_5_words = tmp[tmp<=5]\n",
    "list_min_5_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e6b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.435706Z",
     "start_time": "2022-06-30T19:16:38.430355Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(list_min_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9fc67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.467616Z",
     "start_time": "2022-06-30T19:16:38.438155Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save it \n",
    "\n",
    "list_min_5_words = list(list_min_5_words.index)\n",
    "tmp = pd.DataFrame({\"words\" : list_min_5_words})\n",
    "tmp.to_csv(\"data/cleaned/min_5_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8600ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.494308Z",
     "start_time": "2022-06-30T19:16:38.470468Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# idem for min 10 times\n",
    "\n",
    "tmp = pd.Series(corpus).value_counts()\n",
    "list_min_10_words = tmp[tmp<=10]\n",
    "list_min_10_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd474b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.503468Z",
     "start_time": "2022-06-30T19:16:38.497510Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(list_min_10_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328e285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.526849Z",
     "start_time": "2022-06-30T19:16:38.505886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save it \n",
    "\n",
    "list_min_10_words = list(list_min_10_words.index)\n",
    "tmp = pd.DataFrame({\"words\" : list_min_10_words})\n",
    "tmp.to_csv(\"data/cleaned/min_10_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f9a94",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.3 2nd Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb47469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.537385Z",
     "start_time": "2022-06-30T19:16:38.529204Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_text_2(doc, \n",
    "                   rejoin=False, \n",
    "                   list_rare_words=None, \n",
    "                   min_len_word=3,\n",
    "                   force_is_alpha=True) : \n",
    "    \"\"\"cf process_text_1 but with list_unique_words, min_len_word, and force_is_alpha\n",
    "    \n",
    "    positional arguments : \n",
    "    -----------------------\n",
    "    doc : str : the document (aka a text in str format) to process\n",
    "    \n",
    "    opt args : \n",
    "    -----------------------\n",
    "    rejoin : bool : if True return a string else return the list of tokens\n",
    "    list_rare_words : list : a list of rare words to exclude\n",
    "    min_len_word : int : the minimum length of words to not exclude\n",
    "    force_is_alpha : int : if 1, exclude all tokens with a numeric character\n",
    "    \n",
    "    return : \n",
    "    ------------------------\n",
    "    a string (if rejoin is True) or a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # list_unique_words\n",
    "    if not list_rare_words: \n",
    "        list_rare_words = []\n",
    "        \n",
    "    # lower\n",
    "    doc = doc.lower().strip()\n",
    "    \n",
    "    # tokenize\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # classics stopwords\n",
    "    cleaned_tokens_list = [w for w in raw_tokens_list if w not in stop_words]\n",
    "    \n",
    "    \n",
    "    ###########################################################\n",
    "    ###########################################################\n",
    "    \n",
    "    # no rare tokens\n",
    "    non_rare_tokens = [w for w in cleaned_tokens_list if w not in list_rare_words]\n",
    "    \n",
    "    # no more len words\n",
    "    more_than_N =  [w for w in non_rare_tokens if len(w) >= min_len_word  ]\n",
    "    \n",
    "    # only alpha chars\n",
    "    if force_is_alpha : \n",
    "        alpha_tokens = [w for w in more_than_N if w.isalpha()]\n",
    "    else :\n",
    "        alpha_tokens = more_than_N\n",
    "        \n",
    "    ###########################################################\n",
    "    ###########################################################     \n",
    "    \n",
    "    \n",
    "    # manage return type\n",
    "    if rejoin : \n",
    "        return \" \".join(alpha_tokens)\n",
    "    \n",
    "    return alpha_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a7e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.550849Z",
     "start_time": "2022-06-30T19:16:38.539873Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_tokens_info(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08cac1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:38.559963Z",
     "start_time": "2022-06-30T19:16:38.553237Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441adca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:40.957455Z",
     "start_time": "2022-06-30T19:16:38.563768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus = process_text_2(raw_corpus, \n",
    "                        list_rare_words=list_unique_words, \n",
    "                        rejoin=False)\n",
    "display_tokens_info(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d204c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:40.965455Z",
     "start_time": "2022-06-30T19:16:40.959686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d441b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.4 Stem and Lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a4739",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meanings to one word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae954a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b793577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:40.977945Z",
     "start_time": "2022-06-30T19:16:40.968092Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "doc = \"I have 3 dogs, they was all black. Now they are all white but one of my dog is my favorite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59967f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:40.984510Z",
     "start_time": "2022-06-30T19:16:40.980361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(doc.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47884fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:40.990877Z",
     "start_time": "2022-06-30T19:16:40.986890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trans = PorterStemmer()\n",
    "trans_text = [trans.stem(i) for i in tokens ]\n",
    "print(trans_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29079eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:42.409673Z",
     "start_time": "2022-06-30T19:16:40.992870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trans = WordNetLemmatizer()\n",
    "trans_text = [trans.lemmatize(i) for i in tokens ]\n",
    "print(trans_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b12375",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.5 3rd cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a48b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:42.423525Z",
     "start_time": "2022-06-30T19:16:42.412391Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_text_3(doc, \n",
    "                   rejoin=False, \n",
    "                   lemm_or_stemm=\"stem\",\n",
    "                   list_rare_words=None, \n",
    "                   min_len_word=3,\n",
    "                   force_is_alpha=True) : \n",
    "    \"\"\"cf process_text_2 but with stemm or lem\n",
    "    \n",
    "    positional arguments : \n",
    "    -----------------------\n",
    "    doc : str : the document (aka a text in str format) to process\n",
    "    \n",
    "    opt args : \n",
    "    -----------------------\n",
    "    rejoin : bool : if True return a string else return the list of tokens\n",
    "    lemm_or_stemm : str : if lem do lemmentize else stemmentize  \n",
    "    list_rare_words : list : a list of rare words to exclude\n",
    "    min_len_word : int : the minimum length of words to not exclude\n",
    "    force_is_alpha : int : if 1, exclude all tokens with a numeric character\n",
    "    \n",
    "    return : \n",
    "    ------------------------\n",
    "    a string (if rejoin is True) or a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    # list_unique_words\n",
    "    if not list_rare_words: \n",
    "        list_rare_words = []\n",
    "        \n",
    "    # lower\n",
    "    doc = doc.lower().strip()\n",
    "    \n",
    "    # tokenize\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # classics stopwords\n",
    "    cleaned_tokens_list = [w for w in raw_tokens_list if w not in stop_words]\n",
    "    \n",
    "    # no rare tokens\n",
    "    non_rare_tokens = [w for w in cleaned_tokens_list if w not in list_rare_words]\n",
    "    \n",
    "    # no more len words\n",
    "    more_than_N =  [w for w in non_rare_tokens if len(w) >= min_len_word  ]\n",
    "    \n",
    "    # only alpha chars\n",
    "    if force_is_alpha : \n",
    "        alpha_tokens = [w for w in more_than_N if w.isalpha()]\n",
    "    else :\n",
    "        alpha_tokens = more_than_N\n",
    "\n",
    "        \n",
    "    ###########################################################\n",
    "    ###########################################################\n",
    "    \n",
    "    # stem or lem\n",
    "    if lemm_or_stemm == \"lem\" : \n",
    "        trans = WordNetLemmatizer()\n",
    "        trans_text = [trans.lemmatize(i) for i in alpha_tokens ]\n",
    "    else : \n",
    "        trans = PorterStemmer()\n",
    "        trans_text = [trans.stem(i) for i in alpha_tokens ]\n",
    "        \n",
    "     ###########################################################\n",
    "     ###########################################################\n",
    "    \n",
    "    \n",
    "    # manage return type\n",
    "    if rejoin : \n",
    "        return \" \".join(trans_text)\n",
    "    \n",
    "    return trans_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7400fe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:45.234187Z",
     "start_time": "2022-06-30T19:16:42.425243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# +/- 3s\n",
    "\n",
    "corpus = process_text_3(raw_corpus, rejoin=False, list_rare_words=list_unique_words)\n",
    "pd.Series(corpus).sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28768381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:45.242918Z",
     "start_time": "2022-06-30T19:16:45.236858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8be691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:45.356611Z",
     "start_time": "2022-06-30T19:16:45.245897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.Series( words.words()).sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f275fb7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.5 Only english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7511e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:45.496366Z",
     "start_time": "2022-06-30T19:16:45.358810Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(words.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572bab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:45.617476Z",
     "start_time": "2022-06-30T19:16:45.499137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eng_words = [i.lower() for i in words.words()]\n",
    "eng_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8675c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:45.672510Z",
     "start_time": "2022-06-30T19:16:45.619691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(eng_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc7455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:50.180952Z",
     "start_time": "2022-06-30T19:16:45.674861Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "eng_words_stem = [ps.stem(i) for i in eng_words]\n",
    "display_tokens_info(eng_words_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610242ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:50.228056Z",
     "start_time": "2022-06-30T19:16:50.183245Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(eng_words_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12e9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:51.050928Z",
     "start_time": "2022-06-30T19:16:50.231084Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "eng_words_lem = [lm.lemmatize(i) for i in eng_words]\n",
    "display_tokens_info(eng_words_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189495d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:51.057785Z",
     "start_time": "2022-06-30T19:16:51.053174Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(eng_words_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35dae45",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.6 4th cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a27afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:16:51.072365Z",
     "start_time": "2022-06-30T19:16:51.060451Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_text_4(doc, \n",
    "                   rejoin=False, \n",
    "                   lemm_or_stemm=\"stem\",\n",
    "                   list_rare_words=None, \n",
    "                   min_len_word=3,\n",
    "                   force_is_alpha=True, \n",
    "                   eng_words=None) : \n",
    "    \"\"\"cf process_text_3 but with selection of only english words\n",
    "    \n",
    "    positional arguments : \n",
    "    -----------------------\n",
    "    doc : str : the document (aka a text in str format) to process\n",
    "    \n",
    "    opt args : \n",
    "    -----------------------\n",
    "    rejoin : bool : if True return a string else return the list of tokens\n",
    "    lemm_or_stemm : str : if lem do lemmentize else stemmentize  \n",
    "    list_rare_words : list : a list of rare words to exclude\n",
    "    min_len_word : int : the minimum length of words to not exclude\n",
    "    force_is_alpha : int : if 1, exclude all tokens with a numeric character\n",
    "    eng_words : list : list of english words\n",
    "    \n",
    "    return : \n",
    "    ------------------------\n",
    "    a string (if rejoin is True) or a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # list_unique_words\n",
    "    if not list_rare_words: \n",
    "        list_rare_words = []\n",
    "        \n",
    "    # lower\n",
    "    doc = doc.lower().strip()\n",
    "    \n",
    "    # tokenize\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # classics stopwords\n",
    "    cleaned_tokens_list = [w for w in raw_tokens_list if w not in stop_words]\n",
    "    \n",
    "    # no rare tokens\n",
    "    non_rare_tokens = [w for w in cleaned_tokens_list if w not in list_rare_words]\n",
    "    \n",
    "    # no more len words\n",
    "    more_than_N =  [w for w in non_rare_tokens if len(w) >= min_len_word  ]\n",
    "    \n",
    "    # only alpha chars\n",
    "    if force_is_alpha : \n",
    "        alpha_tokens = [w for w in more_than_N if w.isalpha()]\n",
    "    else :\n",
    "        alpha_tokens = more_than_N\n",
    "\n",
    "    # stem or lem\n",
    "    if lemm_or_stemm == \"lem\" : \n",
    "        trans = WordNetLemmatizer()\n",
    "        trans_text = [trans.lemmatize(i) for i in alpha_tokens ]\n",
    "    else : \n",
    "        trans = PorterStemmer()\n",
    "        trans_text = [trans.stem(i) for i in alpha_tokens ]\n",
    "\n",
    "        \n",
    "    ###########################################################\n",
    "    ###########################################################\n",
    "        \n",
    "    # in english \n",
    "    if eng_words :\n",
    "        engl_text = [i for i in trans_text if i in eng_words]\n",
    "    else :\n",
    "        engl_text = trans_text\n",
    "    \n",
    "    ###########################################################\n",
    "    ###########################################################\n",
    "        \n",
    "        \n",
    "    #  return a list or a string\n",
    "    if rejoin : \n",
    "        return \" \".join(engl_text)\n",
    "    \n",
    "    return engl_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5660a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.880570Z",
     "start_time": "2022-06-30T19:16:51.075362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# +/- 50s\n",
    "corpus = process_text_4(raw_corpus, \n",
    "                        rejoin=False, \n",
    "                        list_rare_words=list_unique_words, \n",
    "                        eng_words=eng_words_stem)\n",
    "display_tokens_info(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181a359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.890030Z",
     "start_time": "2022-06-30T19:17:32.883427Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d12c61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.899219Z",
     "start_time": "2022-06-30T19:17:32.892189Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afb159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.906608Z",
     "start_time": "2022-06-30T19:17:32.901647Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_unique_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f226e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.913628Z",
     "start_time": "2022-06-30T19:17:32.908733Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(list_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9a61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.920663Z",
     "start_time": "2022-06-30T19:17:32.916005Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_min_5_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccce498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:17:32.927143Z",
     "start_time": "2022-06-30T19:17:32.922804Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(list_min_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179c6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:01.689579Z",
     "start_time": "2022-06-30T19:17:32.929569Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# +/- 30 sec\n",
    "corpus = process_text_4(raw_corpus, \n",
    "                        rejoin=False, \n",
    "                        list_rare_words=list_min_5_words, \n",
    "                        eng_words=eng_words_stem)\n",
    "display_tokens_info(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be1c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:01.696083Z",
     "start_time": "2022-06-30T19:18:01.691419Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ee4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:01.710526Z",
     "start_time": "2022-06-30T19:18:01.697803Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.Series(corpus).value_counts()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623efe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:01.715929Z",
     "start_time": "2022-06-30T19:18:01.713177Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.barplot(tmp.index, tmp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed6440",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.7 Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4abba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:02.211910Z",
     "start_time": "2022-06-30T19:18:01.718808Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white', \n",
    "                      stopwords=[], \n",
    "                      max_words=50).generate(\" \".join(corpus))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcda990",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Divide the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841778c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.1 Separate 0 / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12526deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:02.220070Z",
     "start_time": "2022-06-30T19:18:02.214514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df_0 df_1\n",
    "\n",
    "df_1 = df[df.target == 1]\n",
    "df_0 = df[df.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f4a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:50.167320Z",
     "start_time": "2022-06-30T19:18:50.155475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8c3bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fc9b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:02.228354Z",
     "start_time": "2022-06-30T19:18:02.222835Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus_1 = \" \".join(df_1.text)\n",
    "corpus_0 = \" \".join(df_0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab640fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus_1[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5961832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus_0[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec8b8e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.2 Process boths of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d404ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:33.771114Z",
     "start_time": "2022-06-30T19:18:02.231858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpus_1 = process_text_4(corpus_1, \n",
    "                          rejoin=False, \n",
    "                          list_rare_words=list_min_5_words, \n",
    "                          eng_words=eng_words_stem)\n",
    "\n",
    "corpus_0 = process_text_4(corpus_0, \n",
    "                          rejoin=False, \n",
    "                          list_rare_words=list_min_5_words, \n",
    "                          eng_words=eng_words_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa0c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.107120Z",
     "start_time": "2022-06-30T19:18:33.772919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white', \n",
    "                      stopwords=[], \n",
    "                      max_words = 50).generate(\" \".join(corpus_1))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e774a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.513110Z",
     "start_time": "2022-06-30T19:18:34.109810Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white', \n",
    "                      stopwords=[], max_words=50).generate(\" \".join(corpus_0))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dcbe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.524349Z",
     "start_time": "2022-06-30T19:18:34.515883Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.Series(corpus_1).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56913590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.543459Z",
     "start_time": "2022-06-30T19:18:34.534670Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.Series(corpus_0).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf262359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.574288Z",
     "start_time": "2022-06-30T19:18:34.546293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "doublons = [i for i in pd.Series(corpus_1).value_counts().head(n).index \n",
    "     if i in pd.Series(corpus_0).value_counts().head(n).index]\n",
    "doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287dccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.619242Z",
     "start_time": "2022-06-30T19:18:34.576830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "doublons = [i for i in pd.Series(corpus_1).value_counts().head(n).index \n",
    "     if i in pd.Series(corpus_0).value_counts().head(n).index]\n",
    "doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e9139",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4.3 5th cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e9685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.631995Z",
     "start_time": "2022-06-30T19:18:34.622232Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_text_5(doc, \n",
    "                   rejoin=True, \n",
    "                   lemm_or_stemm = \"stem\", \n",
    "                   list_rare_words=None, \n",
    "                   min_len_word=3, \n",
    "                   eng_words=None, \n",
    "                   extra_words=None) : \n",
    "    \"\"\"df v4 but exclude an extra list\"\"\"\n",
    " \n",
    "    # list_unique_words\n",
    "    if not list_rare_words: \n",
    "        list_rare_words = []\n",
    "        \n",
    "    # extra_words\n",
    "    if not extra_words: \n",
    "        extra_words = []\n",
    "        \n",
    "    # lower and strip\n",
    "    doc = doc.lower().strip()\n",
    "    \n",
    "    # tokenize\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # remove stop words\n",
    "    cleaned_tokens_list = [w for w in raw_tokens_list if w not in stop_words]\n",
    "    \n",
    "    # drop rare tokens\n",
    "    non_rare_tokens_list = [w for w in cleaned_tokens_list if w not in list_rare_words]\n",
    "    \n",
    "    # keep only len word > N\n",
    "    more_than_N =  [w for w in non_rare_tokens_list if len(w) >= 3 ]\n",
    "    \n",
    "    # keep only alpha not num\n",
    "    alpha_num = [w for w in more_than_N if w.isalpha()]\n",
    "    \n",
    "    # stem or lem\n",
    "    if lemm_or_stemm == \"lem\" : \n",
    "        trans = WordNetLemmatizer()\n",
    "        trans_text = [trans.lemmatize(i) for i in alpha_num ]\n",
    "    else : \n",
    "        trans = PorterStemmer()\n",
    "        trans_text = [trans.stem(i) for i in alpha_num ]\n",
    "        \n",
    "    # in english \n",
    "    if eng_words :\n",
    "        engl_text = [i for i in trans_text if i in eng_words]\n",
    "    else :\n",
    "        engl_text = trans_text\n",
    "        \n",
    "        \n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    \n",
    "    # drop extra_words tokens\n",
    "    final = [w for w in engl_text if w not in extra_words]\n",
    "    \n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    \n",
    "    \n",
    "    #  return a list or a string\n",
    "    if rejoin : \n",
    "        return \" \".join(final)\n",
    "    \n",
    "    return engl_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a6cd9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5. Final clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b24fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:34.639526Z",
     "start_time": "2022-06-30T19:18:34.635433Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def final_clean(doc) : \n",
    "    \"\"\"perform our final cleaning\"\"\"\n",
    "    \n",
    "    new_doc = process_text_5(doc,\n",
    "                             rejoin=True, \n",
    "                             lemm_or_stemm=\"stem\", \n",
    "                             list_rare_words=list_min_5_words, \n",
    "                             eng_words=eng_words_stem, \n",
    "                             extra_words=doublons)\n",
    "    return  new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0865a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:19:18.935693Z",
     "start_time": "2022-06-30T19:19:04.708276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df[\"clean_text\"] = df.text.apply(final_clean)\n",
    "\n",
    "df[\"clean_text\"] = df.text.parallel_apply(final_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e375f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:50.118646Z",
     "start_time": "2022-06-30T19:18:50.100823Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f534c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:29:20.187563Z",
     "start_time": "2022-06-30T19:29:20.180226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub_df = df[df.target == 1]\n",
    "for idx, ser in sub_df.sample(10).iterrows() : \n",
    "    print(ser['text'])\n",
    "    print(ser['clean_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00653896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:29:32.671198Z",
     "start_time": "2022-06-30T19:29:32.664361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub_df = df[df.target == 0]\n",
    "for idx, ser in sub_df.sample(10).iterrows() : \n",
    "    print(ser['text'])\n",
    "    print(ser['clean_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a0fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:29:37.577564Z",
     "start_time": "2022-06-30T19:29:37.569251Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf82f1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:18:50.151198Z",
     "start_time": "2022-06-30T19:18:50.122229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/cleaned/final_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
